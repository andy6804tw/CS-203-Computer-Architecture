<HTML>
<HEAD>
   <META HTTP-EQUIV="Content-Type" CONTENT="text/html;
charset=iso-8859-1">
   <META NAME="Author" CONTENT="Lilian Atieno">
   <META NAME="GENERATOR" CONTENT="Mozilla/4.03 [en] (X11; I; Linux 2.0.30
i686) [Netscape]">
   <TITLE>Intro</TITLE>
</HEAD>
<BODY TEXT="#000000" BGCOLOR="#FFCC99" LINK="#0000EF" VLINK="#55188A"
ALINK="#FF0000">
&nbsp;
<CENTER><B><FONT FACE="Copperplate Gothic Bold"><FONT SIZE=+3>Effects of resource
utilization on Response time </FONT></FONT></B></CENTER>

<DIV ALIGN=right><FONT FACE="Times New Roman,Times"><FONT SIZE=+1><A HREF="performancehome.html">HOME
</A>/ <A HREF="transaction.html">PREVIOUS</A>/ <A HREF="ref.html">NEXT
</A> </FONT></FONT></DIV>
<P>A naive cost-performance design  assumes 100% utilization of I/O resources. This assumption leads to a servere
increase in <b> response time </b> as we approach 100% utilization. This can be illustrated by a simple
calculation for <b><u>one disk</b></u>, and we will also ignore SCSI
strings and
controller.
<p>
<B>Assumptions:</B>
<i>
<LI>average disk service time=7.8ms</LI>
<LI>poisson arrivals with an exponential service time</LI>
<LI>use M/M/1 queuing model</LI>
</i>
<P>
<B>Characteristics of M/M/1 queue:</b>
<i>
<LI> The system is equilibrium.</LI>
<LI>The times between two successive requests arriving, are exponentially distributed.</LI>
<LI>The number of sources of requests is unlimited (infinite population model).</LI>
<LI>The server can start on the next job immediately after finishing with the prior one.</LI>
<LI>The queue is a FIFO and there is no limit to the length of the queue.</LI>
<LI>There is a single server.</LI>
</i>
<P>
<b>Equations used to evaluate response time:
</b>
<P><B><FONT COLOR="#3366FF">Server utilization</FONT></B>
<P>
<i>=  Arrival rate * Time<SUB>Server</SUB></i>
<P>
<B><FONT COLOR="#3366FF">Time <SUB>queue</SUB></FONT></B>                                
<p>
<i>=  Time<SUB>server</sub> *  Server utilization/(1 - Server
utilization)</i>

<P><B><FONT COLOR="#3366FF">Time <sub>system</sub>(Response
time) </FONT></B>
<P>
<i>= Time<sub>server</sub> + Time<SUB>queue</SUB></i>
<P>
<b>Example: For 64 I/O requests per second</b>
<p>
<i> Server utilization = 64 * 0.0078 = 0.50 ie 50%</i>
<p>
<i>  Time <SUB>queue</SUB> = 7.8ms * 0.50/(1-0.50)  = 7.8ms </i>   
<p>
<i>Time <sub>system</sub>(response time) = 7.8ms + 7.8ms =
15.6ms</i> 
&nbsp;
<BR>&nbsp;
<p><b> The table below shows the server utilization and response time for
differnet request rates.</b>
<CENTER><IMG SRC="Tab1.JPG" HEIGHT=300 WIDTH=500> </CENTER>
<p>
<b>The Graph below plots the response time versus request rate</b>
<CENTER><IMG SRC="ch1.JPG" HEIGHT=600 WIDTH=1050> </CENTER>
<p>
From the graph, we see that <b>100% utilization of disks is quite
unrealistic.</b>  The response time tremendously increases as we try to
use
100% of the server.
<p>
The organization of a realistic cost-performance design should be
performance-tuned. It should be aimed at limiting the utilization
of I/O resources in order to keep reponse time and contention low.
Below is an example of rules of thumb that could guide I/O designers to
meet the above goals:-
<UL>
<LI>
<i> No disk should be used more than 80% of the time</i></LI>

<LI>
<i> No disk arm should be seeking more than 60% of the time</i>.</LI>

<LI>
<i> No disk string should be utilized more than 40%</i>.</LI>

<LI>
<i> No I/O bus should be utilized more than 75%</i></LI>

<P>
<b><i>(The reason the SCSI string bandwidth is set so low is that there is
about a 20% SCSI command overhead on data
transfers, further reducing available bandwidth)</i></b>

</UL>

</BODY>
</HTML>



